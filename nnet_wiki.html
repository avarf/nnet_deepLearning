<!DOCTYPE html>
<html>
<head>
	<title>NNet Tutorial</title>
</head>
<body>
	This is a Wiki for all the notes and tutorials of learning deep learning including resources, code tutorial, theoretical notes and overal movement plan.
<h1>Table of content</h1>
<ol>
	<li><a href="#Resources">Resources</a></li>
	<li><a href="#Movement_Plan">Movement Plan</a> </li>
	<li><a href="#kerastutorial">Keras Tutorial</a></li>
	<ol>
		<li><a href="#kerasLayers">Keras layers</a></li>
		<li><a href="#kerasactivations">Keras activation functions</a></li>
	</ol>
	<li><a href="#TensorFlowBasics">TensorFlow Basics</a></li>
	<ol>
		<li><a href="#Basics_definitions">Basic Definitions</a></li>
	</ol>
	<li><a href="#SimpleNNet">Simple Neural Network</a></li>

	<li><a href="#documentations">Documentations</a></li>
	<ol>
		<li><a href="title_21">Title 2-1</a></li>
		<li><a href="title_22">Title 2-2</a></li>
		<li><a href="title_23">Title 2-3</a></li>

	</ol>

</ol>
<hr>

<h1 id="Resources">Resources</h1>
<ul>
	<li><a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/">Python TensorFlow Tutorial - Build a Neural Network</a></li>

	<li><a href="https://www.datacamp.com/community/blog/keras-cheat-sheet">Keras cheat-sheet</a></li>

	<li><a href=""></a></li>
</ul>
	<h3 id="book_id">Books</h3>
	<ol>
		<li><b>*** Practical Machine Learning with Python</b><br>
	        /home/ali/workspace/nnet_deepLearning/books<br>
	        topics:<br>
	        - Codes: <a href="https://github.com/dipanjanS/practical-machine-learning-with-python">https://github.com/dipanjanS/practical-machine-learning-with-python</a> and also it is downloaded to the book place<br>
	        - frameworks: Keras, TensorFlow ???<br>
	        - Stock: It has a good chapter about stock price forecasting and many good sample codes<br>
	    </li>
		<li><b>*** Pro Deep Learning with TensorFlow:</b><br>
	        /home/ali/workspace/nnet_deepLearning/books<br>
	        topics:<br>
	        - Covers many of the recquired math and theoretical background for deep learning<br>
	        - ToDo: write the rest
	    </li>

		<li><b>Building Machine Learning Projects with TensorFlow</b><br>
			/home/ali/books/TensorFlow<br>
			This book is goog for:" TensorFlow Basics, time series, music, painting"
		</li>
		<li><b>TensorFlow Machine Learning Cookbook</b><br>
			/home/ali/books/TensorFlow<br>
			This book is good for: "TensorFlow Basics, Neural Network, NLP"
		</li>
		<li><b>Deep Learning with TensorFlow</b><br>
			/home/ali/books/TensorFlow<br>
			This book is good for:" Deep Learning models, Neural Networks, text prediction, nlp, emotion detection, android, reinforced learning, Q-learning"
		</li>
		<li><b>Getting Started with TensorFlow</b><br>
			/home/ali/books/TensorFlow<br>
			This book is good for: "Basics, drawing fractals"
		</li>
		
	</ol>
<hr>

<h1 id="Movement_Plan">Movement Plan</h1>
1- Read the "Practical Machine Learning with Python"<br>
2- Learn keras<br>
3- Implement some examples as test
4- Implement Speech recognition and time series forecasting

<hr>
<h1 id="kerastutorial">Keras Tutorial</h1>
<h2 id="kerasBasics">Keras Basics</h2>
<h3>Model:</h3>
A model is a collection of neurons that will define the structure of a neural network. There are two different types of models:
<ol>
	<li>Sequential model:<br>
		Sequential models are just stacks of layers. These layers can together define a neural network.
	</li>
	<li>Functional API Model:<br>
		This API allows us to specify complex networks i.e., networks that can have multiple outputs, networks with shared layers, etc. These kinds of models are needed when we need to use advanced neural networks like convolutional neural networks or recurrent neural networks.
	</li>
</ol>
<h4>Model building</h4>
The model building process with keras is a three-step process:

<ol>
	<li>
		The first step is specifying the structure of the model(sequential or functional).<br>
		Then we enrich that model by adding layers to the model. We will start with the input layer, to which we will feed our input data feature vectors. keras provides a bunch of layers which can be added to the model (hidden layers, fully connected, CNN, LSTM, RNN, and so on). We can stack these layers together in a complex manner and add the final output layer, to arrive at our overall model architecture.
	</li>
	<li>
		Second step is the compilation of the model architecture.<br>
		In the compilation step, we configure the learning process. The learning process, in addition to the structure of the model, needs to specify the following additional three important parameters:
		<ul>
			<li>Optimizer: This could be a string identifier to the already implemented optimizers, a function, or an object to the Optimizer class that we can implement.</li>	
			<li>Loss function: A loss function, also known as an objective function, will specify the objective of minimizing loss/error</li>
			<li>Performance metrics: A metric is a quantifiable measure of the learning process. While compiling a model, we can specify a performance metric we want to track (for example, accuracy for a classification model), which will educate us about the effectiveness of the learning process. This helps in evaluating model performance.</li>
		</ul>
	</li>
	<li>The third step is executing the compiled method to start the training process.</li>
</ol>

<h3>Step 1: creating the structure and architecture of the network</h3>
<h3 id="kerasLayers">Keras layers</h3>
	For the documentation of the rest of the layer types go to: <a href="https://keras.io/layers/about-keras-layers/">About Keras layers</a>
	<ul>
		<li>Dense<br>
			The dense layer means a fully connected layer.<br>
			Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)<br><br>
			units: The number of neurons. ** for the first layer we have to define the size of the input features<br><br>
			activation: the activation function for this layer.<br><br>
			Example:<br>
			model.add(Dense(15, input_dim=30, activation='relu'))<br>
			# The model has 15 neurons/units. Those 15 units (neurons) is fully connected to the 30 input features<br>
			model.add(Dense(1, activation='sigmoid'))<br>
			# The output layer for our example is a dense layer with the sigmoid activation and just one unit. ** after the first layer, you don't need to specify the size of the input anymore.<br><br>
		</li>
		<li>Dropout<br></li>
		<li>Conv1D<br></li>
		<li>Conv2D<br></li>
		<li>Conv3D<br></li>
		<li>SeparableConv2D<br></li>
		<li>Conv2DTranspose<br></li>
		<li>Cropping1D<br></li>
		<li>Cropping2D<br></li>
		<li>Cropping3D<br></li>
		<li>UpSampling1D<br></li>
		<li>UpSampling2D<br></li>
		<li>UpSampling3D<br></li>
		<li>ZeroPadding1D<br></li>
		<li>ZeroPadding2D<br></li>
		<li>ZeroPadding3D<br></li>
		<li>MaxPooling1D<br></li>
		<li>MaxPooling2D<br></li>
		<li>MaxPooling3D<br></li>
		<li>AveragePooling1D<br></li>
		<li>AveragePooling2D<br></li>
		<li>AveragePooling3D<br></li>
		<li>GlobalMaxPooling1D<br></li>
		<li>GlobalMaxPooling2D<br></li>
		<li>GlobalAveragePooling1D<br></li>
		<li>GlobalAveragePooling2D<br></li>
		<li>LocallyConnected1D<br></li>
		<li>LocallyConnected2D<br></li>
		<li>RNN<br></li>
		<li>SimpleRNN<br></li>
		<li>GRU<br></li>
		<li>LSTM<br></li>
		<li>ConvLSTM2D<br></li>
		<li>SimpleRNNCells<br></li>
		<li>CuDNNGRU<br></li>
		<li>CuDNNLSTM<br></li>
		<li>Writing your own Keras layers: <a href="https://keras.io/layers/writing-your-own-keras-layers/">Writing your own Keras layers</a></li>
	</ul>


<h3 id="kerasactivations">Keras activation functions</h3>
Available activation functions are:
<ul>
	<li>softmax</li>
	<li>elu</li>
	<li>selu</li>
	<li>softplus</li>
	<li>softsign</li>
	<li>relu</li>
	<li>tanh</li>
	<li>sigmoid</li>
	<li>hard_sign</li>
	<li>linear</li>
</ul>

<h3>Step2: Defining the compilation of the model</h3>
Once we have defined the model we will then compile the model by supplying the necessary optimizer, loss function, and the metric on which we want to evaluate the model performance.<br><br>

Example:<br>
model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])<br>
Here we used a loss function of binary_crossentropy, which is a standard loss function for binary classification problems. For the optimizer, we used rmsprop, which is an upgrade from the normal gradient descent algorithm.

<h3>Step3: executing the compiled method to start the training process</h3>
The next step is to fit the model using the fit function.<br><br>

Example<br>
model.fit(X_train, y_train, epochs=20, batch_size=50)<br>
Here, the epochs parameter indicates one complete forward and backward pass of all the training examples. The batch_size parameter indicates the total number of samples which are propagated through the NN model at a time for one backward and forward pass for training the model and updating the gradient.<br>
Thus if you have 100 observations and your batch size is 10, each epoch will consist of 10 iterations where 10 observations (data points) will be passed through the network at a time and the weights on the hidden layer units will be updated. However we can see that the overall loss and training accuracy remains the same. Which means the model isnâ€™t really learning anything from the looks of it!<br>

<h4>Step3-2: testing(evaluation) the network</h4>
The API for keras again follows the convention for scikit-learn models, hence we can use the predict function to predict for the data points in the test set. In fact we use predict_classes to get the actual class label predicted for each test data instance.<br><br>

Example:<br>
predictions = model.predict_classes(X_test)<br><br>

Lets evaluate the model performance by looking at the test data accuracy and other performance metrics like precision, recall, and F1 score. Do not despair if you do not understand some of these terms, as we will be covering them in detail in Chapter 5(<b>Practical Machine Learning with Python</b>). For now, you should know that scores closer to 1 indicate better results i.e., an accuracy of 1 would indicate 100% model accuracy, which is perfection. Luckily, scikit-learn provides us with necessary performance metric measuring APIs.<br><br>
Example:<br>
from sklearn import metrics<br>
print('Accuracy:', metrics.accuracy_score(y_true=y_test, y_pred=predictions))<br>
print(metrics.classification_report(y_true=y_test, y_pred=predictions))<br>







<h3 id=""></h3>
<hr>

<h1 id=""></h1>
<hr>
<h1 id=""></h1>
<hr>
<h1 id=""></h1>
<hr>
<h1 id=""></h1>
<hr>
<h1 id=""></h1>
<hr>

<h1 id="TensorFlowBasics">TensorFlow Basics</h1>
<h3 id="Basics_definitions">Basic Definitions</h3>
<ul>
	<li><h3>Constants:</h3><br>
		TensorFlow constants can be declared using the tf.constant function:<br>
		const = tf.constant(2.0, name="const")
	</li>
	<li><h3>Variables:</h3><br>
		TensorFlow variables can be declared using the tf.Variable function:<br>
		b = tf.Variable(2.0, name='b')<br>
		<h3>Note:</h3>
		The first element in both is the value to be assigned the constant / variable when it is initialised.  The second is an optional name string which can be used to label the constant / variable, this is handy for when you want to do visualisations.  TensorFlow will infer the type of the constant / variable from the initialised value, but it can also be set explicitly using the optional dtype argument.  TensorFlow has many of its own types like tf.float32, tf.int32 etc.<br>
		All the constants, variables, operations and the computational graph are only created when the initialisation commands are run.
	</li>
	<li><h3></h3><br></li>
	<li><h3></h3><br></li>
	<li><h3></h3><br></li>

</ul>


In this part we see how we can define a computation graph.
This is an ordered list:<br>
<ol>
	<li>Item 1</li>
	<li>Item 2</li>
	<li>Item 3</li>

</ol>
<hr>
<h1 id="documentations">Documentations</h1>
<ul>
	<li><a href="https://www.tensorflow.org/api_docs/python/tf/DType">TensorFlow data types</a>
	</li>
</ul>
In this section we will see how to build a simple neural network with tensorflow.

<h1 id="title_21">Title 2-1</h1>
<h1 id="title_22">Title 2-2</h1>
<h1 id="title_23">Title 2-3</h1>

</body>
</html>